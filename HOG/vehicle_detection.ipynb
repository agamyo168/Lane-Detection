{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# HOG & Extraction\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "#SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b794e9d",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b89f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars_dir = [car for car in glob.glob(\"../dataset/vehicles/*/*.png\",recursive=True)]\n",
    "non_car_dir = [non_car for non_car in glob.glob(\"../dataset/non-vehicles/*/*.png\",recursive=True)]\n",
    "print(\"Cars loaded: {} Non cars loaded: {}\".format(len(cars_dir),len(non_car_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f3481",
   "metadata": {},
   "source": [
    "#### Loading test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [plt.imread(i) for i in glob.glob(\"../test_images/*.jpg\")]\n",
    "plt.imshow(test_images[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f045a8",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd5d33",
   "metadata": {},
   "source": [
    "#### Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "#     print(features.shape)\n",
    "    return features\n",
    "\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "#     Seems like a useless step each channel for all images return same result\n",
    "#     plt.hist(channel1_hist,bins=32,range=(0,256))\n",
    "#     plt.hist(channel2_hist,bins=32,range=(0,256))\n",
    "#     plt.hist(channel3_hist,bins=32,range=(0,256))\n",
    "#     print(hist_features.shape)\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Return HOG features and visualization\n",
    "# Hog takes only gray images\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualize=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualize=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "def convert_rgb_color(img, conv='YCrCb'):\n",
    "    if conv == 'RGB':\n",
    "        return np.copy(img)\n",
    "    if conv == 'YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    if conv == 'HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    if conv == 'LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    if conv == 'YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "# Extract feature wrapper that extracts and combines all features\n",
    "def extract_features(imgs,params):\n",
    "    cspace= params['color_space']\n",
    "    hog_channel=params['hog_channel']\n",
    "    orient=params['orient']\n",
    "    pix_per_cell= params['pix_per_cell']\n",
    "    cell_per_block=params['cell_per_block']\n",
    "    spatial_size=params['spatial_size']\n",
    "    hist_bins=params['hist_bins']\n",
    "    hist_range=params['hist_range']\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB' \n",
    "        feature_image = convert_rgb_color(image,cspace)\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features) #Join all channels hog features into one feature vector        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range) # Seems useless (?)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features,hog_features))) # Add all features into one feature vector\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "params={}\n",
    "params['color_space'] ='YCrCb'\n",
    "params['hog_channel'] ='ALL'\n",
    "params['orient'] = 9\n",
    "params['pix_per_cell'] = 8\n",
    "params['cell_per_block'] = 2\n",
    "params['spatial_size'] = (32,32)\n",
    "params['hist_bins'] = 32 \n",
    "params['hist_range'] = (0,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe0cab",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3d84f",
   "metadata": {},
   "source": [
    "#### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7344e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "\n",
    "cars_features = extract_features(cars_dir,params)\n",
    "notcars_features = extract_features(non_car_dir,params) \n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t1, 2), 'second to extract features (HOG,spatial and color features).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d139b",
   "metadata": {},
   "source": [
    "#### Data Standardization Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making one feature vector that starts with cars and ends with non_cars\n",
    "X = np.vstack((cars_features, notcars_features)).astype(np.float64)\n",
    "#Computes the mean and standard deviation to be used for later scaling.\n",
    "X_scaler = StandardScaler().fit(X)  #z = (x - u) / s\n",
    "\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X) #Perform standardization by centering and scaling.\n",
    "\n",
    "# scaled_X = StandardScaler().fit_transform(X) #  Does both steps at once\n",
    "# Labeling feature vector <Cars = 1> <Not Cars = 0>\n",
    "y = np.hstack((np.ones(len(cars_dir)), np.zeros(len(non_car_dir))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe236fc",
   "metadata": {},
   "source": [
    "#### Data Split train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = np.random.randint(0, 100) # Store state and also generate random test-train splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "print('Number of samples in train set: ', len(X_train))\n",
    "print('Number of samples in test set: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e538193",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "#Training SVC\n",
    "t1 = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "print(time.time()-t1,'Seconds to train SVC...')\n",
    "# Find accuracy using test set\n",
    "print('SVC Accuracy = {:.4}'.format(svc.score(X_test, y_test)))\n",
    "# Check the prediction time for 100 samples\n",
    "t=time.time()\n",
    "n_predict = 100\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa833b",
   "metadata": {},
   "source": [
    "#### Save to pickle file step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1fc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = {}\n",
    "dist_pickle[\"svc\"] = svc\n",
    "dist_pickle[\"scaler\"] = X_scaler\n",
    "pickle.dump(dist_pickle, open(\"classifier.p\", 'wb') )\n",
    "print('Classifier saved to a pickle file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200b5e4",
   "metadata": {},
   "source": [
    "## Car Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219602b",
   "metadata": {},
   "source": [
    "#### Load classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = {}\n",
    "dist_pickle = pickle.load( open(\"classifier.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Redefining parameters\n",
    "params['svc'] = dist_pickle['svc']\n",
    "params['scaler'] = dist_pickle['scaler']\n",
    "params['color_space'] ='YCrCb'\n",
    "params['hog_channel'] ='ALL'\n",
    "params['orient'] = 9\n",
    "params['pix_per_cell'] = 8\n",
    "params['cell_per_block'] = 2\n",
    "params['cells_per_step'] = 2\n",
    "params['spatial_size'] = (32,32)\n",
    "params['hist_bins'] = 32 \n",
    "params['hist_range'] = (0,256)\n",
    "params['ystart_ystop_scale'] = [(405, 510, 1),(400, 600, 1.5), (500, 710, 2.5) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d79c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cars(img,params, h_shift=0, visualisation=False):\n",
    "     #Parameters:\n",
    "    svc=params['svc']\n",
    "    X_scaler=params['scaler']\n",
    "    orient=params['orient']\n",
    "    cells_per_step = params['cells_per_step']\n",
    "    pix_per_cell=params['pix_per_cell']\n",
    "    cell_per_block=params['cell_per_block']\n",
    "    spatial_size=params['spatial_size']\n",
    "    hist_bins=params['hist_bins']\n",
    "    ystart_ystop_scale = params['ystart_ystop_scale']\n",
    "    \n",
    "    #Boxes\n",
    "    detected_boxes_list = [] # All detected cars in an image\n",
    "    window_visited_list = [] # All windows in an image\n",
    "    \n",
    "    #to make computation efficient by reducing values between 0 to 1\n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    #Searching at different window sizes to get as much detection\n",
    "    for (ystart, ystop, scale) in ystart_ystop_scale:\n",
    "        \n",
    "        #Crop region of interest:\n",
    "        #Far of the camera should have smaller window scale, closer should have bigger window scale.\n",
    "        \n",
    "        search_img = img[ystart:ystop, :, :]\n",
    "        conv_color_img = cv2.cvtColor(search_img, cv2.COLOR_RGB2YCrCb)\n",
    "        \n",
    "        H,W,_ = conv_color_img.shape\n",
    "        if scale != 1:\n",
    "            conv_color_img = cv2.resize(conv_color_img, (np.int(W/scale), np.int(H/scale)))\n",
    "        \n",
    "        ch1 = conv_color_img[:,:,0]\n",
    "        ch2 = conv_color_img[:,:,1]\n",
    "        ch3 = conv_color_img[:,:,2]\n",
    "        \n",
    "        # Define number of blocks:\n",
    "        nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block # All possible x blocks\n",
    "        nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block # All possible y blocks\n",
    "        nfeat_per_block = orient*cell_per_block**2 # Just a measurement of number of features\n",
    "        \n",
    "        # Window size is 64x64\n",
    "        window = 64\n",
    "        #Number of blocks per window\n",
    "        nblocks_per_window = (window // pix_per_cell) - cell_per_block # can also mean no of cells / window\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "        #nxsteps * nysteps = number of windows I think\n",
    "        #print(\"nxsteps:\",nxsteps,\"nysteps:\",nysteps, \"number of windows:\",nxsteps*(nysteps))\n",
    "        \n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        # This is an optimization much better than getting hog for each single window\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        \n",
    "        # Sliding Window\n",
    "        box_vis=[]\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                # Hog cells in x , y\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "#                 print(hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window])\n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "                \n",
    "                # Position of window in pixels in the scaled cropped image\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "                \n",
    "                # Extract the image patch covered by current window\n",
    "                subimg = cv2.resize(conv_color_img[ytop:ytop+window, xleft:xleft+window], (window,window))\n",
    "                \n",
    "                # Get color features\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "                \n",
    "                # Scale features and make a prediction\n",
    "                test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "                \n",
    "                # Make prediction based on trained model \n",
    "                test_prediction = svc.predict(test_features) # Returns 1 if car is detected 0 if not\n",
    "                \n",
    "                if(visualisation): # Draw a box over the real image\n",
    "                    # To view scale and compare it to car sizes\n",
    "                    xbox_left = np.int(xleft*scale) \n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    # Append Detection Position to list \n",
    "                    box_vis.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                # Detected cars go here\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    # Append Detection Position to list \n",
    "                    detected_boxes_list.append(((xbox_left+h_shift, ytop_draw+ystart),(xbox_left+win_draw+h_shift,ytop_draw+win_draw+ystart)))\n",
    "\n",
    "        window_visited_list += [box_vis]\n",
    "    return detected_boxes_list, window_visited_list\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b56b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detection_img = test_images[5]\n",
    "detected,visited = detect_cars(detection_img,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
