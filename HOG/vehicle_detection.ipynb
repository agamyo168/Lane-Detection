{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e4b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# HOG & Extraction\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "#SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b794e9d",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906b89f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars loaded: 8792 Non cars loaded: 8968\n"
     ]
    }
   ],
   "source": [
    "cars_dir = [car for car in glob.glob(\"../dataset/vehicles/*/*.png\",recursive=True)]\n",
    "non_car_dir = [non_car for non_car in glob.glob(\"../dataset/non-vehicles/*/*.png\",recursive=True)]\n",
    "print(\"Cars loaded: {} Non cars loaded: {}\".format(len(cars_dir),len(non_car_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f045a8",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd5d33",
   "metadata": {},
   "source": [
    "#### Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbe9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "#     print(features.shape)\n",
    "    return features\n",
    "\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "#     Seems like a useless step each channel for all images return same result\n",
    "#     plt.hist(channel1_hist,bins=32,range=(0,256))\n",
    "#     plt.hist(channel2_hist,bins=32,range=(0,256))\n",
    "#     plt.hist(channel3_hist,bins=32,range=(0,256))\n",
    "#     print(hist_features.shape)\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Return HOG features and visualization\n",
    "# Hog takes only gray images\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualize=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualize=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "def convert_rgb_color(img, conv='YCrCb'):\n",
    "    if conv == 'RGB':\n",
    "        return np.copy(img)\n",
    "    if conv == 'YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    if conv == 'HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    if conv == 'LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    if conv == 'YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "# Extract feature wrapper that extracts and combines all features\n",
    "def extract_features(imgs,params):\n",
    "    cspace= params['color_space']\n",
    "    hog_channel=params['hog_channel']\n",
    "    orient=params['orient']\n",
    "    pix_per_cell= params['pix_per_cell']\n",
    "    cell_per_block=params['cell_per_block']\n",
    "    spatial_size=params['spatial_size']\n",
    "    hist_bins=params['hist_bins']\n",
    "    hist_range=params['hist_range']\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB' \n",
    "        feature_image = convert_rgb_color(image,cspace)\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features) #Join all channels hog features into one feature vector        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range) # Seems useless (?)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features,hog_features))) # Add all features into one feature vector\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a223d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "params={}\n",
    "params['color_space'] ='YCrCb'\n",
    "params['hog_channel'] ='ALL'\n",
    "params['orient'] = 9\n",
    "params['pix_per_cell'] = 8\n",
    "params['cell_per_block'] = 2\n",
    "params['spatial_size'] = (32,32)\n",
    "params['hist_bins'] = 32 \n",
    "params['hist_range'] = (0,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe0cab",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3d84f",
   "metadata": {},
   "source": [
    "#### Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7344e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672.68 second to extract features (HOG,spatial and color features).\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "\n",
    "cars_features = extract_features(cars_dir,params)\n",
    "notcars_features = extract_features(non_car_dir,params) \n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t1, 2), 'second to extract features (HOG,spatial and color features).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d139b",
   "metadata": {},
   "source": [
    "#### Data Standardization Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfd7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making one feature vector that starts with cars and ends with non_cars\n",
    "X = np.vstack((cars_features, notcars_features)).astype(np.float64)\n",
    "#Computes the mean and standard deviation to be used for later scaling.\n",
    "X_scaler = StandardScaler().fit(X)  #z = (x - u) / s\n",
    "\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X) #Perform standardization by centering and scaling.\n",
    "\n",
    "# scaled_X = StandardScaler().fit_transform(X) #  Does both steps at once\n",
    "# Labeling feature vector <Cars = 1> <Not Cars = 0>\n",
    "y = np.hstack((np.ones(len(cars_dir)), np.zeros(len(non_car_dir))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe236fc",
   "metadata": {},
   "source": [
    "#### Data Split train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199d0ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train set:  14208\n",
      "Number of samples in test set:  3552\n"
     ]
    }
   ],
   "source": [
    "rand_state = np.random.randint(0, 100) # Store state and also generate random test-train splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "print('Number of samples in train set: ', len(X_train))\n",
    "print('Number of samples in test set: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e538193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.279804229736328 Seconds to train SVC...\n",
      "SVC Accuracy = 0.9904\n",
      "My SVC predicts:  [0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 0. 0.]\n",
      "For these 100 labels:  [0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 0. 0.]\n",
      "0.00651 Seconds to predict 100 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "#Training SVC\n",
    "t1 = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "print(time.time()-t1,'Seconds to train SVC...')\n",
    "# Find accuracy using test set\n",
    "print('SVC Accuracy = {:.4}'.format(svc.score(X_test, y_test)))\n",
    "# Check the prediction time for 100 samples\n",
    "t=time.time()\n",
    "n_predict = 100\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa833b",
   "metadata": {},
   "source": [
    "#### Save to pickle file step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1fc81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier saved to a pickle file\n"
     ]
    }
   ],
   "source": [
    "dist_pickle = {}\n",
    "dist_pickle[\"svc\"] = svc\n",
    "dist_pickle[\"scaler\"] = X_scaler\n",
    "pickle.dump(dist_pickle, open(\"classifier.p\", 'wb') )\n",
    "print('Classifier saved to a pickle file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200b5e4",
   "metadata": {},
   "source": [
    "## Car Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219602b",
   "metadata": {},
   "source": [
    "#### Load classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef93f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = {}\n",
    "dist_pickle = pickle.load( open(\"classifier.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30700974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters redefunition \n",
    "params['svc'] = dist_pickle['svc']\n",
    "params['scaler'] = dist_pickle['scaler']\n",
    "params['color_space'] ='YCrCb'\n",
    "params['hog_channel'] ='ALL'\n",
    "params['orient'] = 9\n",
    "params['pix_per_cell'] = 8\n",
    "params['cell_per_block'] = 2\n",
    "params['spatial_size'] = (32,32)\n",
    "params['hist_bins'] = 32 \n",
    "params['hist_range'] = (0,256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
