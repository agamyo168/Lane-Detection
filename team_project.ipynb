{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29305b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "import glob\n",
    "#show matplot images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b93a72",
   "metadata": {},
   "source": [
    "# Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d57a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_image(image,title=\"image\",cmap_type=\"gray\",axis='off'):\n",
    "#     plt.imshow(image,cmap_type)\n",
    "#     plt.title(title)\n",
    "#     plt.axis(axis)\n",
    "\n",
    "#LOADING ALL IMAGES FROM TEST_IMAGES FOLDER\n",
    "images = glob.glob(\"test_images/*.jpg\")\n",
    "images = [plt.imread(image) for image in images] \n",
    "\n",
    "# show_image(images[0],\"FIRST_IMAGE\")\n",
    "\n",
    "def display_images(images, cmap='gray'):\n",
    "    plt.figure(figsize=(40,40))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(5,2,i+1)\n",
    "        plt.imshow(image, cmap)\n",
    "        plt.autoscale(tight=True)\n",
    "    plt.show()\n",
    "display_images(images,None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec610268",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0be9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram Equalizer\n",
    "\n",
    "def hist_equalizer(img):\n",
    "    equ = cv2.equalizeHist(img)\n",
    "    return equ\n",
    "\n",
    "def get_hist(img):\n",
    "    hist = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    return hist\n",
    "\n",
    "def gaussian_blur(img,kernel_size=5):\n",
    "    return cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "\n",
    "def draw_roi(img,isClosed=True,color=(255,0,0),thickness=5):\n",
    "    x,y = (img.shape[1],img.shape[0])\n",
    "    pts = np.array([[0.1,0.95*y], [0.43*x,int(0.65*y)],\n",
    "                [0.58*x,0.65*y], [x,0.95*y]],\n",
    "               np.int32)\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    img = cv2.polylines(img, [pts], \n",
    "                      isClosed, color, \n",
    "                      thickness)\n",
    "    return img\n",
    "\n",
    "def perspective_transform(img,dst_size=(1280,720),inv=0):\n",
    "    img_size=np.float32([(img.shape[1],img.shape[0])])\n",
    "    #Region of Interest\n",
    "    #Order is top left, top right, bottom left, bottom right\n",
    "    src=np.float32([(0.43,0.65),(0.58,0.65),(0.1,0.95),(1,0.95)])\n",
    "    dst=np.float32([(0,0), (1, 0), (0,1), (1,1)])\n",
    "    srcPoints = src*img_size\n",
    "    dstPoints = dst*np.float32(dst_size)\n",
    "    if(inv):\n",
    "        M = cv2.getPerspectiveTransform(dstPoints,srcPoints) #inverse\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(srcPoints,dstPoints) #Returns a matrix that transforms an Image\n",
    "    warped_image = cv2.warpPerspective(img,M,dst_size)\n",
    "    return warped_image \n",
    "\n",
    "def top_hat_filter(img):\n",
    "    #to enhance bright objects of interest in a dark background\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(30,3))\n",
    "    tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    mask = np.zeros_like(tophat)\n",
    "    mask[((tophat >= 10)&(tophat<=150))] = 1\n",
    "    return mask\n",
    "\n",
    "def lane_filter(img):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hls = gaussian_blur(hls,5)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    lab = gaussian_blur(lab,5)\n",
    "    \n",
    "    l_channel = lab[:,:,0]\n",
    "    s_channel = hls[:,:,2]\n",
    "    h_channel = hls[:,:,0]    \n",
    "    \n",
    "    #l_channel works relatively good under bridge and detects white lines\n",
    "    tophat = top_hat_filter(l_channel)\n",
    "    \n",
    "    #Works well with to differentiate colors @sun/dirt\n",
    "    #to detect the colored Lane\n",
    "    s_thresh=(100, 255)\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    combined_binary = np.zeros_like(tophat)\n",
    "    combined_binary[(s_binary == 1) | (tophat == 1)] = 1\n",
    "    # to eliminate noise around lane \n",
    "    #     kernel = np.ones((10,1),np.uint8)\n",
    "#     s_binary = cv2.erode(s_binary,kernel,iterations = 2)\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45263ce5",
   "metadata": {},
   "source": [
    "# Applying filter and prespective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list(map(lane_filter, images))\n",
    "display_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_prespective = list(map(perspective_transform, output))\n",
    "display_images(warped_prespective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586130c",
   "metadata": {},
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globally defined to store the parameters of past images\n",
    "left_a, left_b, left_c = [],[],[]\n",
    "right_a, right_b, right_c = [],[],[]\n",
    "def sliding_window(img, \n",
    "                   nwindows=9, #Number of windows \n",
    "                   margin=150, #half window width 100?\n",
    "                   minpix = 1 #minimum number of pixels to recenter the window 50? \n",
    "                  ):\n",
    "    global left_a, left_b, left_c,right_a, right_b, right_c \n",
    "    left_fit_= np.empty(3) #parameters of 2nd order polynomial\n",
    "    right_fit_ = np.empty(3) \n",
    "    out_img = np.dstack((img, img, img))*255 #Converts binary to 3 dimensional channel normal RGB\n",
    "    \n",
    "    #USING HISTOGRAM METHOD\n",
    "    histogram = get_hist(img) \n",
    "    # find peaks of left and right halves\n",
    "    midpoint = int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    # Indices in image is the coordinates the row is the height is the y\n",
    "    # the column is the width is the x\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 3) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 3) \n",
    "        \n",
    "        #Get non-zero pixels within each window by getting the indices of nonzerox\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0] \n",
    "        #[0] get indices of nonzerox only but you can access nonzeroy with it too\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        ''' \n",
    "        minpix is used to recenter the window and depends on how good the filter is\n",
    "        if minpix is low it might be affected by the noise(?)\n",
    "        therefore we keep minpix at 50 pixels for now to only recenter in the direction of any solid line\n",
    "        '''\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    #All pixels within all 9 windows\n",
    "    left_lane_inds = np.concatenate(left_lane_inds) \n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    #All x and y coordinates for pixels residing inside the 9 windows\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    #Returns three parameters \n",
    "    left_fit = np.polyfit(lefty, leftx,\n",
    "                          2 #Order of the equation\n",
    "                         )\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #ay^2+by+c\n",
    "    #store these three parameters\n",
    "    left_a.append(left_fit[0])\n",
    "    left_b.append(left_fit[1])\n",
    "    left_c.append(left_fit[2])\n",
    "    \n",
    "    right_a.append(right_fit[0])\n",
    "    right_b.append(right_fit[1])\n",
    "    right_c.append(right_fit[2])\n",
    "    \n",
    "    #find the mean for the last 10 frames\n",
    "    left_fit_[0] = np.mean(left_a[-10:])\n",
    "    left_fit_[1] = np.mean(left_b[-10:])\n",
    "    left_fit_[2] = np.mean(left_c[-10:])\n",
    "    \n",
    "    right_fit_[0] = np.mean(right_a[-10:])\n",
    "    right_fit_[1] = np.mean(right_b[-10:])\n",
    "    right_fit_[2] = np.mean(right_c[-10:])\n",
    "    \n",
    "    # Generate x and y values for plotting the two curves\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] ) #the points that will be on the y-axis\n",
    "    left_fitx = left_fit_[0]*ploty**2 + left_fit_[1]*ploty + left_fit_[2] \n",
    "    right_fitx = right_fit_[0]*ploty**2 + right_fit_[1]*ploty + right_fit_[2]\n",
    "    \n",
    "    #Coloring the pixels within the windows\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 100] #Red\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 100, 255] #Blue\n",
    "    \n",
    "    return out_img, (left_fitx, right_fitx), (left_fit_, right_fit_), ploty\n",
    "\n",
    "def draw_lanes(img, left_fit, right_fit,ploty):\n",
    "#     ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    color_img = np.zeros_like(img)\n",
    "    #Horizontal stack #dstack = depth stack #vstack = vertical stack\n",
    "    left = np.array([np.transpose(np.vstack([left_fit, ploty]))])\n",
    "    right = np.array([np.flipud(np.transpose(np.vstack([right_fit, ploty])))]) #flip up to down\n",
    "    points = np.hstack((left, right)) \n",
    "    #Draw two curved lines\n",
    "    cv2.polylines(color_img, np.int_(left) , False, (255,0,0),50) #Red curved line\n",
    "    cv2.polylines(color_img, np.int_(right), False, (0,0,255),50) #Blue curved line\n",
    "    #Draw a polygon of the curve shape\n",
    "    cv2.fillPoly(color_img, np.int_(points), (0,255,0)) #Green curve\n",
    "    inv_perspective = perspective_transform(color_img,inv=1)\n",
    "    inv_perspective = cv2.addWeighted(img, 1, inv_perspective, 0.7, 0)\n",
    "    return inv_perspective,color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_sliding_window(images):\n",
    "#         plt.figure(figsize=(40,40))\n",
    "#         for i, image in enumerate(images):\n",
    "#             out_img, x_points, _, ploty = sliding_window(image)\n",
    "#             img_,birdview_curve = draw_lanes(image, x_points[0], x_points[1],ploty)\n",
    "#             plt.subplot(9,2,i+1)\n",
    "#             plt.imshow(out_img)\n",
    "#             plt.plot(x_points[0], ploty, color='yellow', linewidth=20)\n",
    "#             plt.plot(x_points[1], ploty, color='yellow', linewidth=20)\n",
    "#             plt.imshow(img_)\n",
    "#             plt.autoscale(tight=True)\n",
    "#         plt.show()\n",
    "def cell_sliding_window(warped_image,image):\n",
    "    out_img, x_points, _, ploty = sliding_window(warped_image)\n",
    "    img_,birdview_curve = draw_lanes(image, x_points[0], x_points[1],ploty)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(100, 20))\n",
    "    ax1.imshow(out_img)\n",
    "    ax1.plot(x_points[0], ploty, color='red', linewidth=30)\n",
    "    ax1.plot(x_points[1], ploty, color='blue', linewidth=30)\n",
    "    ax1.set_title('Curves on sliding window', fontsize=100)\n",
    "    ax2.imshow(img_)\n",
    "    ax2.set_title('Original image with overlay', fontsize=100)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,image in enumerate(images):\n",
    "    cell_sliding_window(warped_prespective[i],image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output(img):\n",
    "    img2= pipeline(img)\n",
    "    out_img, curves, lanes, ploty = sliding_window(img2)\n",
    "    img,birdview_curve = draw_lanes(img, curves[0], curves[1],ploty)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c42f0b",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188e99f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('test_images/test3.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "a4mask= pipeline(img)\n",
    "histogram = get_hist(a4mask)\n",
    "# show_image(mask)\n",
    "plt.plot(histogram)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(a4mask, cmap='gray')\n",
    "ax2.set_title('after', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib gtk\n",
    "out_img, curves, lanes, ploty = sliding_window(a4mask)\n",
    "img_,birdview_curve = draw_lanes(img, curves[0], curves[1],ploty)\n",
    "plt.imshow(img_, cmap='hsv')\n",
    "show_image(birdview_curve,\"birdview_overlay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb180e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(100, 20))\n",
    "#f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original', fontsize=100)\n",
    "ax2.imshow(a4mask,'gray')\n",
    "ax2.set_title('Filter+Perspective Tform', fontsize=100)\n",
    "ax3.imshow(out_img)\n",
    "ax3.plot(curves[0], ploty, color='red', linewidth=30)\n",
    "ax3.plot(curves[1], ploty, color='blue', linewidth=30)\n",
    "ax3.set_title('Sliding window+Curve Fit', fontsize=100)\n",
    "ax4.imshow(img_)\n",
    "ax4.set_title('Overlay Lanes', fontsize=100)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9ded2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "right_curves, left_curves = [],[]\n",
    "from moviepy.editor import VideoFileClip\n",
    "myclip = VideoFileClip('project_video.mp4')#.subclip(40,43)\n",
    "output_vid = 'final_fady_project.mp4'\n",
    "clip = myclip.fl_image(final_output)\n",
    "clip.write_videofile(output_vid, fps =25,audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_filter(img,s_thresh=(100, 255), sx_thresh=(15, 255)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    h_channel = hls[:,:,0]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 1) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    ####################################################################################\n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    color_binary = np.dstack((np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    \n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    return combined_binary\n",
    "\n",
    "# def canny_filter(img,threshold=(30,255),s_thresh=(100, 255), l_thresh=(120, 255)):\n",
    "#     # Convert to grayscale\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     height, width = gray.shape\n",
    "#     canny = cv2.Canny(gray,threshold[0],threshold[1])\n",
    "#     # R & G thresholds so that yellow lanes are detected well.\n",
    "#     color_threshold = 150\n",
    "#     R = img[:,:,0]\n",
    "#     G = img[:,:,1]\n",
    "#     color_combined = np.zeros_like(R)\n",
    "#     r_g_condition = (R > color_threshold) & (G > color_threshold)\n",
    "    \n",
    "#     # Apply color threshold for better detection of yello and white lines in all environmental condition\n",
    "#     hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "#     # Select S channel because it is usually the best performant\n",
    "#     # for this task. R channel also performs similarly.\n",
    "#     s_channel = hls[:,:,2] \n",
    "#     l_channel = hls[:,:,1]\n",
    "    \n",
    "#      # S channel performs well for detecting bright yellow and white lanes\n",
    "#     s_condition = (s_channel > s_thresh[0]) & (s_channel <= s_thresh[1])\n",
    "    \n",
    "#     # We put a threshold on the L channel to avoid pixels which have shadows and as a result darker.   \n",
    "#     l_condition = (l_channel > l_thresh[0]) & (l_channel <= l_thresh[1])\n",
    "    \n",
    "#     # combine all the thresholds\n",
    "#     # A pixel should either be a yellowish or whiteish\n",
    "#     # And it should also have a gradient, as per our thresholds\n",
    "#     color_combined[(r_g_condition & l_condition) & (s_condition | canny)] = 1\n",
    "    \n",
    "#     #binary_output[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "#     # apply the region of interest mask\n",
    "#     mask = np.zeros_like(color_combined)\n",
    "#     region_of_interest_vertices = np.array([[0,height-1], [width/2, int(0.5*height)], [width-1, height-1]], dtype=np.int32)\n",
    "#     cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "#     thresholded = cv2.bitwise_and(color_combined, mask)\n",
    "\n",
    "#     return canny\n",
    "# def canny_filter(img,threshold=(20,150)):\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     hist = cv2.equalizeHist(gray)\n",
    "#     canny = cv2.Canny(hist,threshold[0],threshold[1])\n",
    "#     return canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbe14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[5]\n",
    "img2 = sobel_filter(img)\n",
    "height,width = img2.shape\n",
    "# apply the region of interest mask\n",
    "mask = np.zeros_like(img2)\n",
    "region_of_interest_vertices = np.array([[0,height-1], [width/2, int(0.5*height)], [width-1, height-1]], dtype=np.int32)\n",
    "cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "img2 = cv2.bitwise_and(img2, mask)\n",
    "img2 = perspective_transform(img2, dst_size=(1280,720),inv=0)\n",
    "histogram = get_hist(img2)\n",
    "plt.plot(histogram)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(100, 20))\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(img2,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img = images[2]\n",
    "# img_canny = canny_filter(img)\n",
    "# height, width = img_canny.shape\n",
    "# mask = np.zeros_like(img_canny)\n",
    "# region_of_interest_vertices = np.array([[0,0.9*(height-1)], [width/2, int(0.6*height)], [width-1,0.9*( height-1)]], dtype=np.int32)\n",
    "# cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "# img_canny = cv2.bitwise_and(img_canny, mask)\n",
    "# histogram = get_hist(img_canny)\n",
    "\n",
    "# # show_image(mask)\n",
    "# plt.plot(histogram)\n",
    "# f, (ax1, ax2) = plt.subplots(1, 2, figsize=(100, 20))\n",
    "# ax1.imshow(img)\n",
    "# ax2.imshow(img_canny,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37dbc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
